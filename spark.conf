# kerberos details
# https://spark.apache.org/docs/latest/security.html
# mount krb5.conf from config map
#spark.kubernetes.kerberos.krb5.configMapName=krb5-cm
# can mount to a different location and use as krb5.conf
#spark.kubernetes.kerberos.krb5.path=/etc/krb5.conf
# mount hadoop xml files
#spark.kubernetes.hadoop.configMapName=hadoop-cm
# set principal
#spark.kerberos.principal=principal@REALM.COM
# login using a local keytab file
#spark.kerberos.keytab=path_to_keytab
# login using an existing TGT token (ticket cache) available in a secret
#spark.kubernetes.kerberos.tokenSecret.name=
#spark.kubernetes.kerberos.tokenSecret.itemKey

spark.logConf=true
spark.kubernetes.executor.deleteOnTermination=false

# needed for spark 2.4.7
#spark.kubernetes.driverEnv.HTTP2_DISABLE=true

# distributed cache
spark.hadoop.fs.s3a.path.style.access=true
spark.hadoop.fs.s3a.endpoint=play.min.io:9443
spark.hadoop.fs.s3a.connection.ssl.enabled=true
spark.hadoop.fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.access.key=Q3AM3UQ867SPQQA43P2F
spark.hadoop.fs.s3a.secret.key=zuf+tfteSlswRu7BJ86wekitnifILbZam1KYY3TG
spark.kubernetes.file.upload.path=s3a://spark-cache

# history server and logging
spark.eventLog.enabled=true
spark.eventLog.dir=s3a://spark-logs

# ivy cache for maven packages
spark.jars.ivy=/tmp/.ivy

# k8s details
spark.kubernetes.authenticate.driver.serviceAccountName=spark
spark.kubernetes.authenticate.submission.caCertFile=/opt/spark/work-dir/sa-conf/ca.crt
spark.kubernetes.authenticate.submission.oauthTokenFile=/opt/spark/work-dir/sa-conf/sa.token

# k8s application autoscaling
# https://spark.apache.org/docs/latest/configuration.html#dynamic-allocation
#spark.dynamicAllocation.enabled=true
#spark.dynamicAllocation.shuffleTracking.enabled=true
# If dynamic allocation is enabled and an executor has been idle for more than this duration, the executor will be removed.
#spark.dynamicAllocation.executorIdleTimeout=60s

# spark scrap space
# https://spark.apache.org/docs/latest/running-on-kubernetes.html#local-storage
spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.options.claimName=OnDemand
spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.options.storageClass=default
spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.options.sizeLimit=2Gi
spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.mount.path=/data
spark.kubernetes.executor.volumes.persistentVolumeClaim.spark-local-dir-1.mount.readOnly=false
spark.local.dir=/data

# resources
# driver
spark.driver.memory=1g
spark.driver.cores=2
spark.driver.maxResultSize=1g
# executor
spark.executor.instances=2
spark.executor.cores=2
spark.executor.memory=2g

# base image
spark.kubernetes.container.image.pullPolicy=IfNotPresent